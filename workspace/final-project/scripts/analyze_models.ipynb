{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.23.1 in /home/workspace/.local/lib/python3.8/site-packages (1.23.1)\n",
      "Collecting torchvision==0.14.1\n",
      "  Using cached torchvision-0.14.1-cp38-cp38-manylinux2014_aarch64.whl (12.9 MB)\n",
      "Requirement already satisfied: numpy in /home/workspace/.local/lib/python3.8/site-packages (from torchvision==0.14.1) (1.23.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from torchvision==0.14.1) (1.13.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.14.1) (9.5.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision==0.14.1) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision==0.14.1) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.14.1) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.14.1) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.14.1) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.14.1) (2022.12.7)\n",
      "\u001b[31mERROR: pytorch2timeloop 0.2 has requirement numpy==1.21, but you'll have numpy 1.23.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pytorch2timeloop 0.2 has requirement torchvision==0.14, but you'll have torchvision 0.14.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: torchvision\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.14.0\n",
      "    Uninstalling torchvision-0.14.0:\n",
      "      Successfully uninstalled torchvision-0.14.0\n",
      "Successfully installed torchvision-0.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.23.1\n",
    "!pip install torchvision==0.14.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workspace/.local/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "# some basic imports and setups\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import urllib\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model - AlexNet\n",
    "from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "model_url = 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth'\n",
    "\n",
    "class AlexNet_custom(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet_custom, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6)) # in case input image is larger\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# load pretrained weights\n",
    "def alexnet_custom(path = \"model_weights/pretrained_AlexNet.pt\", pretrained=True, progress=True, **kwargs):\n",
    "    model = AlexNet_custom(**kwargs)\n",
    "#     net = torch.jit.load(path)\n",
    "    net = torch.load(path)\n",
    "    params = net.state_dict()\n",
    "#     state_dict = load_state_dict_from_url(model_url, progress=progress)\n",
    "#     model.load_state_dict(state_dict)\n",
    "    model.load_state_dict(params)\n",
    "    return model\n",
    "\n",
    "from collections import namedtuple, OrderedDict, defaultdict\n",
    "class VGG(nn.Module):\n",
    "  ARCH = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
    "\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "\n",
    "    layers = []\n",
    "    counts = defaultdict(int)\n",
    "\n",
    "    def add(name: str, layer: nn.Module) -> None:\n",
    "      layers.append((f\"{name}{counts[name]}\", layer))\n",
    "      counts[name] += 1\n",
    "\n",
    "    in_channels = 3\n",
    "    for x in self.ARCH:\n",
    "      if x != 'M':\n",
    "        # conv-bn-relu\n",
    "        add(\"conv\", nn.Conv2d(in_channels, x, 3, padding=1, bias=False))\n",
    "        add(\"bn\", nn.BatchNorm2d(x))\n",
    "        add(\"relu\", nn.ReLU(True))\n",
    "        in_channels = x\n",
    "      else:\n",
    "        # maxpool\n",
    "        add(\"pool\", nn.MaxPool2d(2))\n",
    "    add(\"avgpool\", nn.AvgPool2d(2))\n",
    "    self.backbone = nn.Sequential(OrderedDict(layers))\n",
    "    self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    # backbone: [N, 3, 32, 32] => [N, 512, 2, 2]\n",
    "    x = self.backbone(x)\n",
    "\n",
    "    # avgpool: [N, 512, 2, 2] => [N, 512]\n",
    "    x = x.mean([2, 3])\n",
    "    x = x.view(x.shape[0], -1)\n",
    "\n",
    "    # classifier: [N, 512] => [N, 10]\n",
    "    x = self.classifier(x)\n",
    "    return x\n",
    "\n",
    "def vgg_custom(path = \"model_weights/pretrained_AlexNet.pt\", pretrained=True, progress=True, **kwargs):\n",
    "    model = VGG(**kwargs)\n",
    "#     net = torch.jit.load(path)\n",
    "    net = torch.load(path, map_location=torch.device('cpu'))\n",
    "    params = net.state_dict()\n",
    "#     state_dict = load_state_dict_from_url(model_url, progress=progress)\n",
    "#     model.load_state_dict(state_dict)\n",
    "    model.load_state_dict(params)\n",
    "    return model\n",
    "\n",
    "\n",
    "net = vgg_custom(path = \"model/8bit_kmeans_quantized.pth\") #pretrained on ImageNet - 1000 classes\n",
    "# net = alexnet_custom(path = \"model_weights/pretrained_AlexNet.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Model eval on CIFAR10\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "classes = ('Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck')\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "  \n",
    "# net = vgg_custom(path = \"model/8bit_kmeans_quantized.pth\") \n",
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for i, data in enumerate(testloader, 0):    #test on 1000 images\n",
    "#         print(i)\n",
    "#         inputs = extra_preprocess(data[0])\n",
    "# #         if i==0 :\n",
    "# #             net = convert_weights(net, inputs.dtype)\n",
    "#         print(net.backbone.conv0.weight.dtype)\n",
    "#         outputs = net(data[0])\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += data[1].size(0)\n",
    "#         correct += (predicted == data[1]).sum().item()\n",
    "#         if i==100:\n",
    "#             break\n",
    "# print('Accuracy of the network on the 1000 test images: %.2f %%' % (100 * correct / total))\n",
    "\n",
    "\n",
    "# def extra_preprocess(x):\n",
    "#     return (x*255 - 128).clamp(-128, 127).to(torch.int8)\n",
    "\n",
    "#pretrained on ImageNet - 1000 classes\n",
    "\n",
    "# net = vgg_custom(path = \"model/8bit_kmeans_quantized.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format input\n",
    "\n",
    "input_tensors = torch.zeros((2500,3,224,224))\n",
    "for i in range(2500):\n",
    "    input_tensors[i,:,:,:] = test_data[0][0]\n",
    "\n",
    "\n",
    "len(input_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit these variables to the correct values\n",
    "#The below are for CIFAR10 AlexNet\n",
    "\n",
    "num_layers = 11\n",
    "layer_type = ['conv','pool','conv','pool','conv','conv','conv','pool','fc','fc','fc'\n",
    "             ]\n",
    "\n",
    "layer_input_sz = [\n",
    "    (50,224,224,3),\n",
    "    (50, 55, 55, 64),\n",
    "    (50, 27, 27, 64),\n",
    "    (50, 27, 27, 192),\n",
    "    (50, 13, 13, 192),\n",
    "    (50, 13, 13, 384),\n",
    "    (50, 13, 13, 256),\n",
    "    (50, 13, 13, 256),\n",
    "    (50, 6, 6, 256),\n",
    "    (50, 4096),\n",
    "    (50, 4096)\n",
    "]\n",
    "\n",
    "layer_param = [\n",
    "    (11,11,3,64,4,4,2),\n",
    "    (3,3,2,2),\n",
    "    (5,5,64,192,1,1,2),\n",
    "    (3,3,2,2),\n",
    "    (3,3,192,384,1,1,1),\n",
    "    (3,3,384,256,1,1,1),\n",
    "    (3,3,256,256,1,1,1),\n",
    "    (3,3,2,2),\n",
    "    (4096,256*6*6),\n",
    "    (4096,4096),\n",
    "    (1000,4096)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Summary:\n",
      "# Type\tInput Size\t\tWeight Param\t\t\t\tOutput Size\t\tWeight Memory\t#mult\n",
      "1 conv\t(50, 224, 224, 3)\t(11, 11, 3, 64, 4, 4, 2)        \t(50, 55, 55, 64)\t93184       \t3513840000  \n",
      "2 pool\t(50, 55, 55, 64)\t(3, 3, 2, 2)                    \t(50, 27, 27, 64)\t0           \t0           \n",
      "3 conv\t(50, 27, 27, 64)\t(5, 5, 64, 192, 1, 1, 2)        \t(50, 27, 27, 192)\t1229568     \t11197440000 \n",
      "4 pool\t(50, 27, 27, 192)\t(3, 3, 2, 2)                    \t(50, 13, 13, 192)\t0           \t0           \n",
      "5 conv\t(50, 13, 13, 192)\t(3, 3, 192, 384, 1, 1, 1)       \t(50, 13, 13, 384)\t2655744     \t5607014400  \n",
      "6 conv\t(50, 13, 13, 384)\t(3, 3, 384, 256, 1, 1, 1)       \t(50, 13, 13, 256)\t3539968     \t7476019200  \n",
      "7 conv\t(50, 13, 13, 256)\t(3, 3, 256, 256, 1, 1, 1)       \t(50, 13, 13, 256)\t2360320     \t4984012800  \n",
      "8 pool\t(50, 13, 13, 256)\t(3, 3, 2, 2)                    \t(50, 6, 6, 256) \t0           \t0           \n",
      "9 fc\t(50, 6, 6, 256) \t(4096, 9216)                    \t(50, 4096)      \t151011328   \t1887436800  \n",
      "10 fc\t(50, 4096)      \t(4096, 4096)                    \t(50, 4096)      \t67125248    \t838860800   \n",
      "11 fc\t(50, 4096)      \t(1000, 4096)                    \t(50, 1000)      \t16388000    \t204800000   \n"
     ]
    }
   ],
   "source": [
    "def get_output_size(inputs_sz, layer_type, layer_param):\n",
    "    \n",
    "    if layer_type == 'conv':\n",
    "        w = int((inputs_sz[1]+2*layer_param[6]-(layer_param[0]-1)-1)/layer_param[4]) +1\n",
    "        h = int((inputs_sz[2]+2*layer_param[6]-(layer_param[1]-1)-1)/layer_param[5]) +1\n",
    "        return (inputs_sz[0], w, h,layer_param[3])\n",
    "    \n",
    "    elif layer_type == 'pool':\n",
    "        w = int((inputs_sz[1]-(layer_param[0]-1)-1)/layer_param[2]) +1\n",
    "        h = int((inputs_sz[2]-(layer_param[1]-1)-1)/layer_param[3]) +1\n",
    "        return (inputs_sz[0], w, h,inputs_sz[3])\n",
    "\n",
    "    elif layer_type == 'fc':\n",
    "        return (inputs_sz[0], layer_param[0])\n",
    "\n",
    "\n",
    "def num_params(layer_type, layer_param):\n",
    "    \n",
    "    if layer_type == 'conv':\n",
    "        return ((layer_param[0]*layer_param[1]*layer_param[2])+1)*layer_param[3]\n",
    "\n",
    "    elif layer_type == 'pool':\n",
    "        return 0\n",
    "    \n",
    "    elif layer_type == 'fc':\n",
    "        return (layer_param[1]*layer_param[0])+1*layer_param[0]\n",
    "\n",
    "# Required memory in bytes\n",
    "def param_memory_size(layer_type, layer_param):    \n",
    "    param_numbr = num_params(layer_type, layer_param)\n",
    "    return param_numbr*4\n",
    "\n",
    "\n",
    "def num_mult(input_sz, layer_type, layer_param):\n",
    "    \n",
    "    if layer_type == 'conv':\n",
    "        (batch_size, width, height, channels) = get_output_size(input_sz, layer_type, layer_param)\n",
    "        return (batch_size*(width*height*channels)*(layer_param[0]*layer_param[1]*layer_param[2]))\n",
    "\n",
    "    elif layer_type == 'pool':\n",
    "        return 0\n",
    "    \n",
    "    elif layer_type == 'fc':\n",
    "        return (input_sz[0]*layer_param[0]*layer_param[1])\n",
    "\n",
    "\n",
    "layer_output_sz = []\n",
    "layer_params_mem = []\n",
    "layer_mult_count = []\n",
    "\n",
    "for n in range(num_layers):\n",
    "    layer_output_sz.append(get_output_size(layer_input_sz[n], layer_type[n], layer_param[n]))\n",
    "    layer_params_mem.append(param_memory_size(layer_type[n], layer_param[n]))\n",
    "    layer_mult_count.append(num_mult(layer_input_sz[n], layer_type[n], layer_param[n]))\n",
    "\n",
    "print(\"Network Summary:\")\n",
    "print(\"# Type\\tInput Size\\t\\tWeight Param\\t\\t\\t\\tOutput Size\\t\\tWeight Memory\\t#mult\")\n",
    "for layer_idx in range(num_layers):\n",
    "    print(\"%d %s\\t%s\\t%s\\t%s\\t%s\\t%s\" % (\n",
    "            (layer_idx+1),\n",
    "            layer_type[layer_idx], \n",
    "            str(layer_input_sz[layer_idx]).ljust(16), \n",
    "            str(layer_param[layer_idx]).ljust(32), \n",
    "            str(layer_output_sz[layer_idx]).ljust(16), \n",
    "            str(layer_params_mem[layer_idx]).ljust(12),\n",
    "            str(layer_mult_count[layer_idx]).ljust(12)\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VGG' object has no attribute 'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m         inp \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mclassifier[i](inp)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m act\n\u001b[0;32m---> 17\u001b[0m act \u001b[38;5;241m=\u001b[39m \u001b[43mget_activations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m, in \u001b[0;36mget_activations\u001b[0;34m(net, input_tensors)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m l:\n\u001b[1;32m      6\u001b[0m         act \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [inp\u001b[38;5;241m.\u001b[39mdetach()]\n\u001b[0;32m----> 7\u001b[0m     inp \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m[i](inp)\n\u001b[1;32m      8\u001b[0m inp \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mavgpool(inp)\n\u001b[1;32m      9\u001b[0m inp \u001b[38;5;241m=\u001b[39m inp\u001b[38;5;241m.\u001b[39mview(inp\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m256\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m6\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m6\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1265\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1264\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1265\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1266\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VGG' object has no attribute 'features'"
     ]
    }
   ],
   "source": [
    "def get_activations(net, input_tensors):\n",
    "    inp = input_tensors; k = \"features\"; act = []\n",
    "    l = [0, 3, 6, 8, 10]\n",
    "    for i in range(12):\n",
    "        if i in l:\n",
    "            act += [inp.detach()]\n",
    "        inp = net.features[i](inp)\n",
    "    inp = net.avgpool(inp)\n",
    "    inp = inp.view(inp.size(0), 256 * 6 * 6)\n",
    "    l = [1, 4, 6]\n",
    "    for i in range(7):\n",
    "        if i in l:\n",
    "            act += [inp.detach()]\n",
    "        inp = net.classifier[i](inp)\n",
    "    return act\n",
    "\n",
    "act = get_activations(net, input_tensors[1].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer\tTotal\tZeros\tZero Percentage\n",
      "1\t150528\t0\t0\n",
      "2\t46656\t19027\t40.7815\n",
      "3\t32448\t14843\t45.744\n",
      "4\t64896\t53806\t82.9111\n",
      "5\t43264\t34947\t80.7762\n",
      "6\t9216\t7597\t82.4327\n",
      "7\t4096\t3365\t82.1533\n",
      "8\t4096\t3556\t86.8164\n"
     ]
    }
   ],
   "source": [
    "print(\"Layer\\tTotal\\tZeros\\tZero Percentage\")\n",
    "nonzero_sum = 0\n",
    "tot_sum = 0\n",
    "zero_count = []\n",
    "for i in range(len(act)):\n",
    "    act_i = act[i].numpy()\n",
    "    tot, zeros = act_i.size, np.count_nonzero(act_i==0)\n",
    "    zero_count += [zeros]\n",
    "    nonzero_sum += tot-zeros\n",
    "    tot_sum += tot\n",
    "    frac = 100.0*zeros/tot\n",
    "    print(\"%d\\t%d\\t%d\\t%g\" % (i+1, tot, zeros, frac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Mul\tNon-Zero Mul\tNon-Zero Percentage\n",
      "35709424000\t33216204450\t93.018\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_mult = 0\n",
    "zero_mult = 0\n",
    "i=0\n",
    "for n in range(num_layers):\n",
    "    num_multi = num_mult(layer_input_sz[n], layer_type[n], layer_param[n])\n",
    "    total_mult += num_multi\n",
    "    if layer_type[n] == 'conv':\n",
    "        zer = layer_input_sz[n][0]*zero_count[i]*layer_param[n][0]*layer_param[n][1] #Assuming each zero in the input activation will involve in kernel_width x kernel_height multiplications\n",
    "        zero_mult += zer\n",
    "        i += 1\n",
    "#         print (zer)\n",
    "    if layer_type[n] == 'fc':\n",
    "        zer = layer_input_sz[n][0]*zero_count[i]*layer_param[n][0]\n",
    "        zero_mult += zer\n",
    "        i += 1\n",
    "#         print (zer)\n",
    "    \n",
    "        \n",
    "non_zero_mult = total_mult - zero_mult\n",
    "\n",
    "frac = 100.0*non_zero_mult/total_mult\n",
    "# ----------\n",
    "\n",
    "print(\"Total Mul\\tNon-Zero Mul\\tNon-Zero Percentage\")\n",
    "print(\"%d\\t%d\\t%g\" % (total_mult, non_zero_mult, frac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelergyTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown module type <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "unknown module type <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "unknown module type <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "unknown module type <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "unknown module type <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "unknown module type <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "unknown module type <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "unknown module type <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "unknown module type <class 'torch.nn.modules.pooling.AvgPool2d'>\n",
      "unknown module type <class '__main__.VGG'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running timeloop to get energy and latency...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:39<04:34, 39.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace/final-project/scripts/../example_designs/simple_output_stationary/vgg_8bit/layer1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 2/8 [02:49<09:16, 92.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace/final-project/scripts/../example_designs/simple_output_stationary/vgg_8bit/layer2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 3/8 [06:23<12:19, 147.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace/final-project/scripts/../example_designs/simple_output_stationary/vgg_8bit/layer3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 4/8 [10:23<12:17, 184.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace/final-project/scripts/../example_designs/simple_output_stationary/vgg_8bit/layer4\n"
     ]
    }
   ],
   "source": [
    "# some basic imports and setups\n",
    "\n",
    "import profiler\n",
    "from profiler import Profiler\n",
    "import torchvision\n",
    "\n",
    "profiler = Profiler(\n",
    "        top_dir='./../workloads',\n",
    "        sub_dir='vgg_8bit',\n",
    "        timeloop_dir='./../example_designs',\n",
    "        design = 'simple_output_stationary',\n",
    "        model=net,\n",
    "        input_size=(3, 224, 224),\n",
    "        batch_size=1,\n",
    "        convert_fc=True,\n",
    "        exception_module_names=[]\n",
    "    )\n",
    "results = profiler.profile()\n",
    "\n",
    "total_energy = 0\n",
    "total_cycle = 0\n",
    "\n",
    "for layer_id, info in results.items():\n",
    "    print(f\"ID: {layer_id} \\t Energy: {info['energy']} \\t Cycle: {info['cycle']} \\t Number of same architecture layers: {info['num']}\")\n",
    "    total_energy += info['energy'] * info['num']\n",
    "    total_cycle += info['cycle'] * info['num']\n",
    "    \n",
    "print(f'\\nTotal Energy: {total_energy} uj \\nTotal Cycles: {total_cycle}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
